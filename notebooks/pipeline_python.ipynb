{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41346a31",
   "metadata": {},
   "source": [
    "## 📦 Librerías y Configuración Inicial\n",
    "\n",
    "Para nuestros ejemplos, usaremos las siguientes librerías esenciales en ingeniería de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "776f4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd          # Manipulación y análisis de datos\n",
    "import sqlite3              # Base de datos SQL ligera\n",
    "import numpy as np          # Operaciones numéricas\n",
    "import json                 # Manejo de datos JSON\n",
    "import logging              # Sistema de logs\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de logging para monitorear el pipeline\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6e3c3",
   "metadata": {},
   "source": [
    "# Extraemos los datos atravez de la base de datos en excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c117c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_database() -> pd.DataFrame:\n",
    "\n",
    "    try:\n",
    "        logger.info(\"Iniciando extracción de datos...\")\n",
    "        \n",
    "        # Cargar los datos\n",
    "         # Cargar los datos\n",
    "        file_path = '..\\\\data\\\\raw\\\\Paper1_WebData_Final.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        print(\"--- 1. Datos Crudos Extraídos ---\")\n",
    "        print(f\"Registros extraídos: {len(df)}\")\n",
    "        print(f\"Columnas: {list(df.columns)}\")\n",
    "        print(\"\\nPrimeras filas:\")\n",
    "        print(df)\n",
    "        print(\"\\nInformación del DataFrame:\")\n",
    "        print(df.info())\n",
    "        print('')\n",
    "        \n",
    "        logger.info(f\"Extracción completada: {len(df)} registros\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en la extracción: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded65010",
   "metadata": {},
   "source": [
    "# Testeamos la extraccion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13a05505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 21:37:52,128 - INFO - Iniciando extracción de datos...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Datos Crudos Extraídos ---\n",
      "Registros extraídos: 1114966\n",
      "Columnas: ['test_date', 'nid', 'L500k', 'L1k', 'L2k', 'L3k', 'L4k', 'L6k', 'L8k', 'R500k', 'R1k', 'R2k', 'R3k', 'R4k', 'R6k', 'R8k', 'gender', 'naics', 'age_group', 'region', 'NAICS_descr']\n",
      "\n",
      "Primeras filas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 21:37:54,535 - INFO - Extracción completada: 1114966 registros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           test_date      nid  L500k   L1k   L2k   L3k   L4k   L6k   L8k  \\\n",
      "0        12-FEB-2007        1   10.0   5.0   5.0  15.0   5.0   0.0  20.0   \n",
      "1        29-FEB-2008        2   15.0   5.0  15.0  20.0  20.0  15.0  15.0   \n",
      "2        08-FEB-2006        3   25.0  20.0  15.0  20.0  35.0  25.0  15.0   \n",
      "3        29-FEB-2008        6   10.0  10.0  10.0  35.0  50.0  30.0  10.0   \n",
      "4        08-FEB-2006        8   15.0  15.0   5.0  15.0  45.0  30.0  20.0   \n",
      "...              ...      ...    ...   ...   ...   ...   ...   ...   ...   \n",
      "1114961  11-DEC-2001  3214185   20.0  15.0  20.0  15.0  25.0  15.0  25.0   \n",
      "1114962  02-DEC-2002  3214186    5.0   5.0  15.0  50.0  60.0  55.0  25.0   \n",
      "1114963  31-JAN-2001  3214187   10.0   5.0   5.0   0.0  10.0  10.0  10.0   \n",
      "1114964  13-MAR-2001  3214189   10.0   0.0   5.0   0.0  10.0  15.0  10.0   \n",
      "1114965  13-MAR-2001  3214191    5.0   5.0  10.0  15.0  10.0  15.0  35.0   \n",
      "\n",
      "         R500k  ...   R2k   R3k   R4k   R6k   R8k  gender   naics  age_group  \\\n",
      "0         20.0  ...  10.0  10.0  25.0  30.0  45.0       M  331512          4   \n",
      "1         10.0  ...  10.0  15.0  30.0  20.0  15.0       M  331512          3   \n",
      "2         20.0  ...  10.0  15.0  40.0  30.0  30.0       M  331512          3   \n",
      "3         10.0  ...   5.0  30.0  35.0  25.0  20.0       M  331512          4   \n",
      "4         15.0  ...   5.0  40.0  50.0  20.0   5.0       M  331512          3   \n",
      "...        ...  ...   ...   ...   ...   ...   ...     ...     ...        ...   \n",
      "1114961   15.0  ...  10.0  15.0  20.0  20.0  15.0       M  334418          3   \n",
      "1114962   10.0  ...  30.0  55.0  60.0  55.0  50.0       M  334418          4   \n",
      "1114963    5.0  ...   0.0   5.0   5.0  15.0  10.0       M  334418          1   \n",
      "1114964    5.0  ...   5.0   5.0  10.0  10.0  10.0       F  334418          1   \n",
      "1114965   30.0  ...  25.0  15.0  10.0  30.0  25.0       M  334418          3   \n",
      "\n",
      "         region                                        NAICS_descr  \n",
      "0            MA                         Steel Investment Foundries  \n",
      "1            MA                         Steel Investment Foundries  \n",
      "2            MA                         Steel Investment Foundries  \n",
      "3            MA                         Steel Investment Foundries  \n",
      "4            MA                         Steel Investment Foundries  \n",
      "...         ...                                                ...  \n",
      "1114961      MW  Printed Circuit Assembly (Electronic Assembly)...  \n",
      "1114962      MW  Printed Circuit Assembly (Electronic Assembly)...  \n",
      "1114963      MW  Printed Circuit Assembly (Electronic Assembly)...  \n",
      "1114964      MW  Printed Circuit Assembly (Electronic Assembly)...  \n",
      "1114965      MW  Printed Circuit Assembly (Electronic Assembly)...  \n",
      "\n",
      "[1114966 rows x 21 columns]\n",
      "\n",
      "Información del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1114966 entries, 0 to 1114965\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   test_date    1114966 non-null  object \n",
      " 1   nid          1114966 non-null  int64  \n",
      " 2   L500k        1114910 non-null  float64\n",
      " 3   L1k          1114900 non-null  float64\n",
      " 4   L2k          1114905 non-null  float64\n",
      " 5   L3k          1114905 non-null  float64\n",
      " 6   L4k          1114932 non-null  float64\n",
      " 7   L6k          1114889 non-null  float64\n",
      " 8   L8k          1112680 non-null  float64\n",
      " 9   R500k        1114897 non-null  float64\n",
      " 10  R1k          1114896 non-null  float64\n",
      " 11  R2k          1114893 non-null  float64\n",
      " 12  R3k          1114899 non-null  float64\n",
      " 13  R4k          1114914 non-null  float64\n",
      " 14  R6k          1114868 non-null  float64\n",
      " 15  R8k          1112659 non-null  float64\n",
      " 16  gender       1111722 non-null  object \n",
      " 17  naics        1114966 non-null  int64  \n",
      " 18  age_group    1114966 non-null  int64  \n",
      " 19  region       1086910 non-null  object \n",
      " 20  NAICS_descr  1114966 non-null  object \n",
      "dtypes: float64(14), int64(3), object(4)\n",
      "memory usage: 178.6+ MB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = extract_from_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6f22f",
   "metadata": {},
   "source": [
    "## Parte del proceso EDA: Exploración de los datos\n",
    "\n",
    "En esta etapa del análisis exploratorio de datos (EDA), nos enfocamos en examinar el tipo de datos con los que estamos trabajando, así como en entender sus distribuciones y su significado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "705fcf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 21:37:54,558 - INFO - Verificando distribución de datos...\n",
      "2025-09-06 21:37:56,104 - INFO - Distribución verificada.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          test_date           nid         L500k           L1k           L2k  \\\n",
      "count       1114966  1.114966e+06  1.114910e+06  1.114900e+06  1.114905e+06   \n",
      "unique         3137           NaN           NaN           NaN           NaN   \n",
      "top     05-MAR-2008           NaN           NaN           NaN           NaN   \n",
      "freq           2879           NaN           NaN           NaN           NaN   \n",
      "mean            NaN  1.793365e+06  9.533200e+00  8.793782e+00  1.138195e+01   \n",
      "std             NaN  1.113799e+06  2.050912e+01  2.181823e+01  2.547234e+01   \n",
      "min             NaN  1.000000e+00 -1.000000e+01 -1.000000e+01 -1.000000e+01   \n",
      "25%             NaN  4.963842e+05  5.000000e+00  5.000000e+00  5.000000e+00   \n",
      "50%             NaN  2.311976e+06  1.000000e+01  5.000000e+00  1.000000e+01   \n",
      "75%             NaN  2.644766e+06  1.500000e+01  1.000000e+01  1.500000e+01   \n",
      "max             NaN  3.214191e+06  9.990000e+02  9.990000e+02  9.990000e+02   \n",
      "\n",
      "                 L3k           L4k           L6k           L8k         R500k  \\\n",
      "count   1.114905e+06  1.114932e+06  1.114889e+06  1.112680e+06  1.114897e+06   \n",
      "unique           NaN           NaN           NaN           NaN           NaN   \n",
      "top              NaN           NaN           NaN           NaN           NaN   \n",
      "freq             NaN           NaN           NaN           NaN           NaN   \n",
      "mean    1.681822e+01  2.132418e+01  2.422573e+01  2.982228e+02  9.455482e+00   \n",
      "std     3.009114e+01  3.439405e+01  4.202559e+01  4.411005e+02  2.050305e+01   \n",
      "min    -1.000000e+01 -1.000000e+01 -1.000000e+01 -1.000000e+01 -1.000000e+01   \n",
      "25%     5.000000e+00  5.000000e+00  1.000000e+01  1.000000e+01  5.000000e+00   \n",
      "50%     1.000000e+01  1.500000e+01  2.000000e+01  2.500000e+01  1.000000e+01   \n",
      "75%     2.000000e+01  3.000000e+01  3.000000e+01  9.990000e+02  1.000000e+01   \n",
      "max     9.990000e+02  9.990000e+02  9.990000e+02  9.990000e+02  9.990000e+02   \n",
      "\n",
      "        ...           R2k           R3k           R4k           R6k  \\\n",
      "count   ...  1.114893e+06  1.114899e+06  1.114914e+06  1.114868e+06   \n",
      "unique  ...           NaN           NaN           NaN           NaN   \n",
      "top     ...           NaN           NaN           NaN           NaN   \n",
      "freq    ...           NaN           NaN           NaN           NaN   \n",
      "mean    ...  1.035448e+01  1.497123e+01  1.946783e+01  2.261212e+01   \n",
      "std     ...  2.521201e+01  2.976380e+01  3.420095e+01  4.190192e+01   \n",
      "min     ... -1.000000e+01 -1.000000e+01 -1.000000e+01 -1.000000e+01   \n",
      "25%     ...  0.000000e+00  5.000000e+00  5.000000e+00  1.000000e+01   \n",
      "50%     ...  5.000000e+00  1.000000e+01  1.500000e+01  1.500000e+01   \n",
      "75%     ...  1.500000e+01  2.000000e+01  2.500000e+01  3.000000e+01   \n",
      "max     ...  9.990000e+02  9.990000e+02  9.990000e+02  9.990000e+02   \n",
      "\n",
      "                 R8k   gender         naics     age_group   region  \\\n",
      "count   1.112659e+06  1111722  1.114966e+06  1.114966e+06  1086910   \n",
      "unique           NaN        2           NaN           NaN        6   \n",
      "top              NaN        M           NaN           NaN       MW   \n",
      "freq             NaN   864130           NaN           NaN   525090   \n",
      "mean    2.976399e+02      NaN  3.828768e+05  2.845540e+00      NaN   \n",
      "std     4.414629e+02      NaN  1.300063e+05  1.239987e+00      NaN   \n",
      "min    -1.000000e+01      NaN  2.210000e+02  1.000000e+00      NaN   \n",
      "25%     1.000000e+01      NaN  3.222150e+05  2.000000e+00      NaN   \n",
      "50%     2.500000e+01      NaN  3.334120e+05  3.000000e+00      NaN   \n",
      "75%     9.990000e+02      NaN  4.413100e+05  4.000000e+00      NaN   \n",
      "max     9.990000e+02      NaN  9.281100e+05  5.000000e+00      NaN   \n",
      "\n",
      "                                   NAICS_descr  \n",
      "count                                  1114966  \n",
      "unique                                     735  \n",
      "top     Couriers and Express Delivery Services  \n",
      "freq                                     99831  \n",
      "mean                                       NaN  \n",
      "std                                        NaN  \n",
      "min                                        NaN  \n",
      "25%                                        NaN  \n",
      "50%                                        NaN  \n",
      "75%                                        NaN  \n",
      "max                                        NaN  \n",
      "\n",
      "[11 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "def ver_distribucion(df: pd.DataFrame):\n",
    "    try:\n",
    "        logger.info(\"Verificando distribución de datos...\")\n",
    "        print(df.describe(include='all'))\n",
    "        logger.info(\"Distribución verificada.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al verificar distribución: {str(e)}\")\n",
    "        raise\n",
    "ver_distribucion(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c345a",
   "metadata": {},
   "source": [
    "# Ahora vamos a verificar el tipo de dato de todas las colunas y si es necesario cambiarlo :\n",
    "columna | tipo de dato\n",
    "- test_date      String (fecha)\n",
    "- nid           numerico\n",
    "- L500k         numerico\n",
    "- L1k           numerico\n",
    "- L2k           numerico\n",
    "- L3k           numerico\n",
    "- L4k           numerico\n",
    "- L6k           numerico\n",
    "- L8k           numerico\n",
    "- R500k         numerico\n",
    "- R1k           numerico\n",
    "- R2k           numerico\n",
    "- R3k           numerico\n",
    "- R4k           numerico\n",
    "- R6k           numerico\n",
    "- R8k           numerico\n",
    "- gender         String\n",
    "- naics          Numerico #North American Industry Classification System 2007 code\n",
    "- age_group      Numerico #Age group (1= 1825 years; 2 = 2635; 3 = 3645; 4 = 4655; 5 = 5665)\n",
    "- region         String\n",
    "- NAICS_descr    String North American Industry Classification System 2007 code industry title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb04232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Tipo de Datos por Columna ---\n",
      "            Data Type\n",
      "test_date      object\n",
      "nid             int64\n",
      "L500k         float64\n",
      "L1k           float64\n",
      "L2k           float64\n",
      "L3k           float64\n",
      "L4k           float64\n",
      "L6k           float64\n",
      "L8k           float64\n",
      "R500k         float64\n",
      "R1k           float64\n",
      "R2k           float64\n",
      "R3k           float64\n",
      "R4k           float64\n",
      "R6k           float64\n",
      "R8k           float64\n",
      "gender         object\n",
      "naics           int64\n",
      "age_group       int64\n",
      "region         object\n",
      "NAICS_descr    object\n",
      "\n",
      "Parceamos los tipo de dato\n",
      "\n",
      "--- 4. Tipo de Datos Después del Parseo ---\n",
      "            Data Type\n",
      "test_date      object\n",
      "nid             int64\n",
      "L500k         float64\n",
      "L1k           float64\n",
      "L2k           float64\n",
      "L3k           float64\n",
      "L4k           float64\n",
      "L6k           float64\n",
      "L8k           float64\n",
      "R500k         float64\n",
      "R1k           float64\n",
      "R2k           float64\n",
      "R3k           float64\n",
      "R4k           float64\n",
      "R6k           float64\n",
      "R8k           float64\n",
      "gender         object\n",
      "naics           int64\n",
      "age_group       int64\n",
      "region         object\n",
      "NAICS_descr    object\n"
     ]
    }
   ],
   "source": [
    "def check_type_data(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    type_data = df.dtypes\n",
    "    type_df = pd.DataFrame({'Data Type': type_data})\n",
    "    print(\"\\n--- 3. Tipo de Datos por Columna ---\")\n",
    "    print(type_df)\n",
    "\n",
    "    print(\"\\nParceamos los tipo de dato\")\n",
    "    columnas_numericas = [\"nid\",'naics','L500k', 'L1k', 'L2k', 'L3k', 'L4k', 'L6k', 'L8k', 'R500k', 'R1k', 'R2k', 'R3k', 'R4k', 'R6k', 'R8k' ,\"age_group\"]\n",
    "    columnas_string = [\"gender\",\"region\",\"NAICS_descr\"]\n",
    "    columnas_fecha = [\"test_date\"] \n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in columnas_numericas:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        elif col in columnas_string:\n",
    "            df[col] = df[col].astype('string')\n",
    "        elif col in columnas_fecha:\n",
    "            df[col] = pd.to_datetime(df[col], format='%d-%m-%Y', errors='coerce')\n",
    "        else:\n",
    "            print(f\"Columna no categorizada: {col}\")\n",
    "\n",
    "    print(\"\\n--- 4. Tipo de Datos Después del Parseo ---\")\n",
    "    print(type_df)\n",
    "    return df\n",
    "df = check_type_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306ed56",
   "metadata": {},
   "source": [
    "## Ahora vamos a hallar los datos vacios y los vamos a remplazar con medidas de tendencia central (esto es parte de la transformacaón (EDA))\n",
    "hay algunos datos como 999 998 997 los cuales representan ademas de los datos nulos:\n",
    "- 997 = refusal to test (esta fila la podemos eliminar)\n",
    "- 998 = no response at maximum value (podemos remplazarlo con el dato maximo)\n",
    "- 999 = not tested (podemos remplazarlo con medidas de tendencia central)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b61e588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Datos Faltantes por Columna ---\n",
      "             Missing Values  Percentage\n",
      "test_date           1755373  157.437357\n",
      "region               668463   59.953667\n",
      "gender               643651   57.728307\n",
      "R8k                  642714   57.644269\n",
      "L8k                  642693   57.642386\n",
      "R6k                  640505   57.446146\n",
      "L6k                  640484   57.444263\n",
      "R2k                  640480   57.443904\n",
      "R1k                  640477   57.443635\n",
      "R500k                640476   57.443545\n",
      "R3k                  640474   57.443366\n",
      "L1k                  640473   57.443276\n",
      "L2k                  640468   57.442828\n",
      "L3k                  640468   57.442828\n",
      "L500k                640463   57.442379\n",
      "R4k                  640459   57.442021\n",
      "L4k                  640441   57.440406\n",
      "nid                  640407   57.437357\n",
      "naics                640407   57.437357\n",
      "age_group            640407   57.437357\n",
      "NAICS_descr          640407   57.437357\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_date</th>\n",
       "      <td>1755373</td>\n",
       "      <td>157.437357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>668463</td>\n",
       "      <td>59.953667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>643651</td>\n",
       "      <td>57.728307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R8k</th>\n",
       "      <td>642714</td>\n",
       "      <td>57.644269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L8k</th>\n",
       "      <td>642693</td>\n",
       "      <td>57.642386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R6k</th>\n",
       "      <td>640505</td>\n",
       "      <td>57.446146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L6k</th>\n",
       "      <td>640484</td>\n",
       "      <td>57.444263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2k</th>\n",
       "      <td>640480</td>\n",
       "      <td>57.443904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R1k</th>\n",
       "      <td>640477</td>\n",
       "      <td>57.443635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R500k</th>\n",
       "      <td>640476</td>\n",
       "      <td>57.443545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R3k</th>\n",
       "      <td>640474</td>\n",
       "      <td>57.443366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1k</th>\n",
       "      <td>640473</td>\n",
       "      <td>57.443276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2k</th>\n",
       "      <td>640468</td>\n",
       "      <td>57.442828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3k</th>\n",
       "      <td>640468</td>\n",
       "      <td>57.442828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L500k</th>\n",
       "      <td>640463</td>\n",
       "      <td>57.442379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R4k</th>\n",
       "      <td>640459</td>\n",
       "      <td>57.442021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L4k</th>\n",
       "      <td>640441</td>\n",
       "      <td>57.440406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nid</th>\n",
       "      <td>640407</td>\n",
       "      <td>57.437357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naics</th>\n",
       "      <td>640407</td>\n",
       "      <td>57.437357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <td>640407</td>\n",
       "      <td>57.437357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAICS_descr</th>\n",
       "      <td>640407</td>\n",
       "      <td>57.437357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Missing Values  Percentage\n",
       "test_date           1755373  157.437357\n",
       "region               668463   59.953667\n",
       "gender               643651   57.728307\n",
       "R8k                  642714   57.644269\n",
       "L8k                  642693   57.642386\n",
       "R6k                  640505   57.446146\n",
       "L6k                  640484   57.444263\n",
       "R2k                  640480   57.443904\n",
       "R1k                  640477   57.443635\n",
       "R500k                640476   57.443545\n",
       "R3k                  640474   57.443366\n",
       "L1k                  640473   57.443276\n",
       "L2k                  640468   57.442828\n",
       "L3k                  640468   57.442828\n",
       "L500k                640463   57.442379\n",
       "R4k                  640459   57.442021\n",
       "L4k                  640441   57.440406\n",
       "nid                  640407   57.437357\n",
       "naics                640407   57.437357\n",
       "age_group            640407   57.437357\n",
       "NAICS_descr          640407   57.437357"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# miramos cuantos datos nulos hay en cada columna\n",
    "def check_missing_data(df):\n",
    "    missing_data = df.isnull().sum()\n",
    "    # buscamos 997 998 999 en las columnas de frecuencias de la audiometria\n",
    "    colums_to_check = ['L500k', 'L1k', 'L2k', 'L3k', 'L4k', 'L6k', 'L8k', 'R500k', 'R1k', 'R2k', 'R3k', 'R4k', 'R6k', 'R8k', 'gender']\n",
    "    for col in colums_to_check:\n",
    "        if col in df.columns:\n",
    "            missing_data += df[col].isin([997, 998, 999]).sum()\n",
    "    missing_percentage = (missing_data / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({'Missing Values': missing_data, 'Percentage': missing_percentage})\n",
    "    missing_df = missing_df[missing_df['Missing Values'] > 0].sort_values(by='Missing Values', ascending=False)\n",
    "    \n",
    "    print(\"\\n--- 2. Datos Faltantes por Columna ---\")\n",
    "    print(missing_df)\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "check_missing_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7055c438",
   "metadata": {},
   "source": [
    "## Ahora vemos ha usar tecnicas de imputacion de datos para remplazar los datos falantes\n",
    "- tambien se va a realizar el cambio de nombres de las columnas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c92e2e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 21:37:58,427 - INFO - Iniciando transformación de datos...\n",
      "2025-09-06 21:37:59,837 - INFO - Transformación completada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "def transform_data(df:pd.DataFrame):\n",
    "    try:\n",
    "        \n",
    "        logger.info(\"Iniciando transformación de datos...\")\n",
    "    \n",
    "        df.replace([997, 998, 999], np.nan, inplace=True)\n",
    "\n",
    "        # Hallamos el promedio de las columnas de frecuencias de la audiometria que no son nulas\n",
    "        columnas_frecuencias =['L500k', 'L1k', 'L2k', 'L3k', 'L4k', 'L6k', 'L8k', 'R500k', 'R1k', 'R2k', 'R3k', 'R4k', 'R6k', 'R8k']\n",
    "        promedios = df[columnas_frecuencias].mean()\n",
    "\n",
    "\n",
    "        # Rellenar NaN con el promedio correspondiente\n",
    "        df[columnas_frecuencias] = df[columnas_frecuencias].fillna(promedios)\n",
    "        logger.info(\"Transformación completada exitosamente.\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en la transformación: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "df = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcc664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
